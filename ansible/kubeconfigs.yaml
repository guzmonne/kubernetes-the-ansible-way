---
- name: Kubeconfigs creation
  hosts: local
  connection: local
  gather_facts: no
  vars_files:
    - secret.yml
  tasks:
    - name: Get worker nodes
      ec2_instance_facts:
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        aws_region: '{{ aws_region }}'
        filters:
          "tag:Type": worker
          instance-state-name: ["running"]
      register: worker_nodes

    - name: Create the kubeconfig files for the worker nodes
      include_tasks: ./tasks/client_kubeconfig.yaml
      loop: '{{ worker_nodes.instances }}'

    - name: Check if the kube-proxy.kubeconfig file exists
      stat:
        path: './kubeconfigs/kube-proxy.kubeconfig'
      register: kube_proxy

    - name: Create the kube-proxy.kubeconfig file
      shell: >
        kubectl config set-cluster {{ project_name }} \
          --certificate-authority=./tls/ca.pem \
          --embed-certs=true \
          --server=https://{{ kubernetes_api_public_uri }}:6443 \
          --kubeconfig=./kubeconfigs/kube-proxy.kubeconfig ;\

        kubectl config set-credentials system:kube-proxy \
          --client-certificate=./tls/kube-proxy.pem \
          --client-key=./tls/kube-proxy-key.pem \
          --embed-certs=true \
          --kubeconfig=./kubeconfigs/kube-proxy.kubeconfig ;\

        kubectl config set-context default \
          --cluster={{ project_name }} \
          --user=system:kube-proxy \
          --kubeconfig=./kubeconfigs/kube-proxy.kubeconfig

        kubectl config use-context default \
          --kubeconfig=./kubeconfigs/kube-proxy.kubeconfig
      when: kube_proxy.stat.exists == False

    - name: Check if the kube-controller-manager.kubeconfig file exists
      stat:
        path: './kubeconfigs/kube-controller-manager.kubeconfig'
      register: kube_controller_manager

    - name: Create the kube-controller-manager.kubeconfig file
      shell: >
        kubectl config set-cluster {{ project_name }} \
          --certificate-authority=./tls/ca.pem \
          --embed-certs=true \
          --server=https://127.0.0.1:6443 \
          --kubeconfig=./kubeconfigs/kube-controller-manager.kubeconfig ;\

        kubectl config set-credentials system:kube-controller-manager \
          --client-certificate=./tls/kube-controller-manager.pem \
          --client-key=./tls/kube-controller-manager-key.pem \
          --embed-certs=true \
          --kubeconfig=./kubeconfigs/kube-controller-manager.kubeconfig ;\

        kubectl config set-context default \
          --cluster={{ project_name }} \
          --user=system:kube-controller-manager \
          --kubeconfig=./kubeconfigs/kube-controller-manager.kubeconfig

        kubectl config use-context default \
          --kubeconfig=./kubeconfigs/kube-controller-manager.kubeconfig
      when: kube_controller_manager.stat.exists == False

    - name: Check if the kube-scheduler.kubeconfig file exists
      stat:
        path: './kubeconfigs/kube-scheduler.kubeconfig'
      register: kube_scheduler

    - name: Create the kube-scheduler.kubeconfig file
      shell: >
        kubectl config set-cluster {{ project_name }} \
          --certificate-authority=./tls/ca.pem \
          --embed-certs=true \
          --server=https://127.0.0.1:6443 \
          --kubeconfig=./kubeconfigs/kube-scheduler.kubeconfig ;\

        kubectl config set-credentials system:kube-scheduler \
          --client-certificate=./tls/kube-scheduler.pem \
          --client-key=./tls/kube-scheduler-key.pem \
          --embed-certs=true \
          --kubeconfig=./kubeconfigs/kube-scheduler.kubeconfig ;\

        kubectl config set-context default \
          --cluster={{ project_name }} \
          --user=system:kube-scheduler \
          --kubeconfig=./kubeconfigs/kube-scheduler.kubeconfig

        kubectl config use-context default \
          --kubeconfig=./kubeconfigs/kube-scheduler.kubeconfig
      when: kube_scheduler.stat.exists == False

    - name: Check if the admin.kubeconfig file exists
      stat:
        path: './kubeconfigs/admin.kubeconfig'
      register: admin

    - name: Create the admin.kubeconfig file
      shell: >
        kubectl config set-cluster {{ project_name }} \
          --certificate-authority=./tls/ca.pem \
          --embed-certs=true \
          --server=https://127.0.0.1:6443 \
          --kubeconfig=./kubeconfigs/admin.kubeconfig ;\

        kubectl config set-credentials admin \
          --client-certificate=./tls/admin.pem \
          --client-key=./tls/admin-key.pem \
          --embed-certs=true \
          --kubeconfig=./kubeconfigs/admin.kubeconfig ;\

        kubectl config set-context default \
          --cluster={{ project_name }} \
          --user=system:admin \
          --kubeconfig=./kubeconfigs/admin.kubeconfig

        kubectl config use-context default \
          --kubeconfig=./kubeconfigs/admin.kubeconfig
      when: admin.stat.exists == False

- name: Create Master and Worker groups
  hosts: local
  connection: local
  gather_facts: no
  vars_files:
    - secret.yml
  tags:
    - copy
  tasks:
    - name: Get bastion node
      ec2_instance_facts:
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        aws_region: '{{ aws_region }}'
        filters:
          "tag:Type": bastion
          instance-state-name: ["running"]
      register: bastion_nodes

    - name: Get the IP address of the bastion
      set_fact:
        bastion_public_ip: '{{ bastion_nodes.instances[0].public_ip_address }}'

    - name: Get worker nodes
      ec2_instance_facts:
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        aws_region: '{{ aws_region }}'
        filters:
          "tag:Type": worker
          instance-state-name: ["running"]
      register: worker_nodes
    
    - name: Create the workers group
      add_host:
        name: '{{ item.instance_id }}'
        group: workers
        instance_id: '{{ item.instance_id }}'
        ansible_host: '{{ item.network_interfaces[0].private_ip_address }}'
        ansible_ssh_private_key_file: ./output/kube.pem
        ansible_ssh_user: ubuntu
        ansible_python_interpreter: /usr/bin/python3
        ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o ProxyCommand="ssh -W %h:%p -i ./output/kube.pem -q ubuntu@{{ bastion_public_ip }} -o StrictHostKeyChecking=no"'
      loop: '{{ worker_nodes.instances }}'

    - name: Get master nodes
      ec2_instance_facts:
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        aws_region: '{{ aws_region }}'
        filters:
          "tag:Type": master
          instance-state-name: ["running"]
      register: master_nodes
    
    - name: Create the masters group
      add_host:
        name: '{{ item.instance_id }}'
        group: masters
        instance_id: '{{ item.instance_id }}'
        ansible_host: '{{ item.network_interfaces[0].private_ip_address }}'
        ansible_ssh_private_key_file: ./output/kube.pem
        ansible_ssh_user: ubuntu
        ansible_python_interpreter: /usr/bin/python3
        ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o ProxyCommand="ssh -W %h:%p -i ./output/kube.pem -q ubuntu@{{ bastion_public_ip }} -o StrictHostKeyChecking=no"'
      loop: '{{ master_nodes.instances }}'

- name: Copy kubeconfigs to Worker nodes
  hosts: workers
  gather_facts: no
  vars_files:
    - secret.yml
  tags:
    - copy
  tasks:
    - name: Copy the workers kubeconfigs
      copy:
        src: './kubeconfigs/{{ instance_id }}.kubeconfig'
        dest: '/home/{{ ansible_ssh_user }}/{{ instance_id }}.kubeconfig'
        mode: '0644'
    
    - name: Copy the kube-proxy kubeconfigs
      copy:
        src: './kubeconfigs/kube-proxy.kubeconfig'
        dest: '/home/{{ ansible_ssh_user }}/kube-proxy.kubeconfig'
        mode: '0644'

- name: Copy the masters kubecofigs
  hosts: masters
  gather_facts: no
  vars_files:
    - secret.yml
  tags:
    - copy
  tasks:
    - name: Copy the kube-controller-manager kubeconfigs
      copy:
        src: './kubeconfigs/kube-controller-manager.kubeconfig'
        dest: '/home/{{ ansible_ssh_user }}/kube-controller-manager.kubeconfig'
        mode: '0644'

    - name: Copy the admin kubeconfigs
      copy:
        src: './kubeconfigs/admin.kubeconfig'
        dest: '/home/{{ ansible_ssh_user }}/admin.kubeconfig'
        mode: '0644' 

    - name: Copy the kube-scheduler kubeconfigs
      copy:
        src: './kubeconfigs/kube-scheduler.kubeconfig'
        dest: '/home/{{ ansible_ssh_user }}/kube-scheduler.kubeconfig'
        mode: '0644' 
    